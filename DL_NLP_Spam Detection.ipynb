{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import keras\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "#https://www.kaggle.com/uciml/sms-spam-collection-dataset\n",
    "data = pd.read_csv('spam.csv', encoding = \"ISO-8859-1\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      "v1            5572 non-null object\n",
      "v2            5572 non-null object\n",
      "Unnamed: 2    50 non-null object\n",
      "Unnamed: 3    12 non-null object\n",
      "Unnamed: 4    6 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data = data[['v1', 'v2']]\n",
    "email_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_data = email_data.rename(columns={'v1':'Target', 'v2':'Email'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go jurong point, crazy.. Available bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry 2 wkly comp win FA Cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say early hor... U c already say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I think goes usf, lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target                                              Email\n",
       "0    ham  Go jurong point, crazy.. Available bugis n gre...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry 2 wkly comp win FA Cup final tkts 2...\n",
       "3    ham          U dun say early hor... U c already say...\n",
       "4    ham          Nah I think goes usf, lives around though"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove stop words\n",
    "stop = stopwords.words('english')\n",
    "email_data['Email'] = email_data['Email'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "email_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point  crazy   available bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar    joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor    u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i think goes usf  lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target                                              Email\n",
       "0    ham  go jurong point  crazy   available bugis n gre...\n",
       "1    ham                      ok lar    joking wif u oni   \n",
       "2   spam  free entry 2 wkly comp win fa cup final tkts 2...\n",
       "3    ham          u dun say early hor    u c already say   \n",
       "4    ham          nah i think goes usf  lives around though"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove punnctuation and connvert to lower\n",
    "email_data['Email'] = email_data['Email'].apply(lambda x: re.sub('[!@#$:).;,?&]', \" \", x.lower()))\n",
    "email_data['Email'] = email_data['Email'].apply(lambda x: re.sub(' ',' ', x))\n",
    "email_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate text(input) and target class\n",
    "target = email_data['Target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preparation and model building\n",
    "train, test = train_test_split(email_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sequence lengths, max number of words and embedding dimensions\n",
    "max_seq_len = 300\n",
    "# Top 20000 frequently occurring words\n",
    "max_num_words = 20000\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=max_num_words)\n",
    "tokenizer.fit_on_texts(train.Email)\n",
    "train_sequence = tokenizer.texts_to_sequences(train.Email)\n",
    "test_sequence = tokenizer.texts_to_sequences(test.Email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7906 unique tokens\n"
     ]
    }
   ],
   "source": [
    "#dictionary containing words and thier index\n",
    "word_index = tokenizer.word_index\n",
    "print('Found {} unique tokens').format(len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting only the top frequent words\n",
    "from keras.preprocessing import sequence\n",
    "train_data = sequence.pad_sequences(train_sequence, maxlen = max_seq_len)\n",
    "test_data = sequence.pad_sequences(test_sequence, maxlen = max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 300)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115, 300)\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train['Target']\n",
    "test_labels = test['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#convert character array to numeric array\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels = le.transform(train_labels)\n",
    "test_labels = le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'ham' u'spam']\n"
     ]
    }
   ],
   "source": [
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([3854,  603]))\n",
      "(array([0, 1]), array([971, 144]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_labels, return_counts=True))\n",
    "print(np.unique(test_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of data tensor:', (4457, 300))\n",
      "('Shape of label tensor:', (4457, 2))\n",
      "('Shape of label tensor:', (1115, 2))\n"
     ]
    }
   ],
   "source": [
    "#changing data types\n",
    "from keras.utils.np_utils import to_categorical\n",
    "labels_train = to_categorical(np.asarray(train_labels))\n",
    "labels_test = to_categorical(np.asarray(test_labels))\n",
    "print('Shape of data tensor:', train_data.shape)\n",
    "print('Shape of label tensor:', labels_train.shape)\n",
    "print('Shape of label tensor:', labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model building....#import libraries\n",
    "from keras.layers import Dense, Input, Dropout, Activation, LSTM, Embedding, MaxPooling1D, GlobalMaxPool1D\n",
    "from keras.layers import Bidirectional, Conv1D, SimpleRNN, BatchNormalization, Flatten\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_num_words, Embedding_dim, input_length=max_seq_len))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/oluwolealowolodu/anaconda3/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/5\n",
      "4457/4457 [==============================] - 32s 7ms/step - loss: 0.3760 - acc: 0.8506 - val_loss: 0.2705 - val_acc: 0.8852\n",
      "Epoch 2/5\n",
      "4457/4457 [==============================] - 28s 6ms/step - loss: 0.2770 - acc: 0.8853 - val_loss: 0.2558 - val_acc: 0.8843\n",
      "Epoch 3/5\n",
      "4457/4457 [==============================] - 27s 6ms/step - loss: 0.2124 - acc: 0.9195 - val_loss: 0.1597 - val_acc: 0.9507\n",
      "Epoch 4/5\n",
      "4457/4457 [==============================] - 28s 6ms/step - loss: 0.1511 - acc: 0.9509 - val_loss: 0.1326 - val_acc: 0.9516\n",
      "Epoch 5/5\n",
      "4457/4457 [==============================] - 29s 7ms/step - loss: 0.1387 - acc: 0.9592 - val_loss: 0.1441 - val_acc: 0.9444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1332f4d0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the model\n",
    "model.fit(train_data, labels_train, batch_size=64, epochs=5, \n",
    "          validation_data=(test_data, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9833114 , 0.01668858],\n",
       "       [0.9833114 , 0.01668858],\n",
       "       [0.99216485, 0.00783512],\n",
       "       ...,\n",
       "       [0.9833114 , 0.01668858],\n",
       "       [0.98925346, 0.01074661],\n",
       "       [0.9861034 , 0.01389665]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model.predict(test_data)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.94083414 0.98809524]\n",
      "recall: [0.99897013 0.57638889]\n",
      "fscore: [0.96903097 0.72807018]\n",
      "support: [971 144]\n",
      "############################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       971\n",
      "           1       0.99      0.58      0.73       144\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1115\n",
      "   macro avg       0.96      0.79      0.85      1115\n",
      "weighted avg       0.95      0.94      0.94      1115\n",
      " samples avg       0.94      0.94      0.94      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "precision, recall, fscore, support = score(labels_test,predicted.round())\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print(\"############################\")\n",
    "print(metrics.classification_report(labels_test, predicted.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing library\n",
    "from keras.layers.recurrent import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_num_words, Embedding_dim, input_length=max_seq_len))\n",
    "model.add(SimpleRNN(2, input_shape=(None, 1)))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/5\n",
      "4457/4457 [==============================] - 60s 13ms/step - loss: 0.3672 - acc: 0.9441 - val_loss: 0.1949 - val_acc: 0.9857\n",
      "Epoch 2/5\n",
      "4457/4457 [==============================] - 53s 12ms/step - loss: 0.1342 - acc: 0.9906 - val_loss: 0.1109 - val_acc: 0.9874\n",
      "Epoch 3/5\n",
      "4457/4457 [==============================] - 51s 11ms/step - loss: 0.0702 - acc: 0.9955 - val_loss: 0.0881 - val_acc: 0.9857\n",
      "Epoch 4/5\n",
      "4457/4457 [==============================] - 51s 12ms/step - loss: 0.0426 - acc: 0.9980 - val_loss: 0.0805 - val_acc: 0.9830\n",
      "Epoch 5/5\n",
      "4457/4457 [==============================] - 53s 12ms/step - loss: 0.0281 - acc: 0.9993 - val_loss: 0.0699 - val_acc: 0.9830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a35146b50>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, labels_train, batch_size=16, epochs=5,\n",
    "         validation_data=(test_data, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98319894, 0.01680109],\n",
       "       [0.9824455 , 0.01755449],\n",
       "       [0.9869097 , 0.01309026],\n",
       "       ...,\n",
       "       [0.9865031 , 0.01349682],\n",
       "       [0.9817378 , 0.01826221],\n",
       "       [0.9667154 , 0.03328463]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction on test data\n",
    "predicted_srnn = model.predict(test_data)\n",
    "predicted_srnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.98373984 0.97709924]\n",
      "recall: [0.9969104  0.88888889]\n",
      "fscore: [0.99028133 0.93090909]\n",
      "support: [971 144]\n",
      "############################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       971\n",
      "           1       0.98      0.89      0.93       144\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1115\n",
      "   macro avg       0.98      0.94      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      " samples avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "precision, recall, fscore, support = score(labels_test, predicted_srnn.round())\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print(\"############################\")\n",
    "print(metrics.classification_report(labels_test, predicted_srnn.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oluwolealowolodu/anaconda3/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(units=16, return_sequences=True, activation=\"relu\", recurrent_activation=\"hard_sigmoid\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_num_words, Embedding_dim, input_length=max_seq_len))\n",
    "model.add(LSTM(output_dim=16, activation='relu', inner_activation='hard_sigmoid',\n",
    "               return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/5\n",
      "4457/4457 [==============================] - 191s 43ms/step - loss: 0.1452 - acc: 0.9464 - val_loss: 0.4384 - val_acc: 0.7982\n",
      "Epoch 2/5\n",
      "4457/4457 [==============================] - 181s 41ms/step - loss: 0.0171 - acc: 0.9948 - val_loss: 0.0587 - val_acc: 0.9857\n",
      "Epoch 3/5\n",
      "4457/4457 [==============================] - 165s 37ms/step - loss: 0.0032 - acc: 0.9993 - val_loss: 0.0592 - val_acc: 0.9857\n",
      "Epoch 4/5\n",
      "4457/4457 [==============================] - 169s 38ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0729 - val_acc: 0.9848\n",
      "Epoch 5/5\n",
      "4457/4457 [==============================] - 180s 40ms/step - loss: 7.7984e-04 - acc: 0.9998 - val_loss: 0.0793 - val_acc: 0.9865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a495bf3d0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, labels_train, batch_size=16, epochs=5,\n",
    "         validation_data=(test_data, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9986076e-01, 1.3921251e-04],\n",
       "       [9.9999285e-01, 7.1840141e-06],\n",
       "       [1.0000000e+00, 5.7008892e-10],\n",
       "       ...,\n",
       "       [9.9994648e-01, 5.3544303e-05],\n",
       "       [9.9999881e-01, 1.1379519e-06],\n",
       "       [9.9640638e-01, 3.5936092e-03]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction on test data\n",
    "predicted_lstm = model.predict(test_data)\n",
    "predicted_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.98676171 0.98496241]\n",
      "recall: [0.99794027 0.90972222]\n",
      "fscore: [0.99231951 0.94584838]\n",
      "support: [971 144]\n",
      "############################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       971\n",
      "           1       0.98      0.91      0.95       144\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1115\n",
      "   macro avg       0.99      0.95      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      " samples avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, support = score(labels_test, predicted_lstm.round())\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print(\"############################\")\n",
    "print(metrics.classification_report(labels_test, predicted_lstm.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  Sequential()\n",
    "model.add(Embedding(max_num_words, Embedding_dim, input_length=max_seq_len))\n",
    "model.add(Bidirectional(LSTM(16, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)))\n",
    "model.add(Conv1D(16, kernel_size=3, padding='valid', kernel_initializer = \"glorot_uniform\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/oluwolealowolodu/anaconda3/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/3\n",
      "4457/4457 [==============================] - 348s 78ms/step - loss: 0.1711 - acc: 0.9408 - val_loss: 0.0420 - val_acc: 0.9865\n",
      "Epoch 2/3\n",
      "4457/4457 [==============================] - 316s 71ms/step - loss: 0.0165 - acc: 0.9957 - val_loss: 0.0435 - val_acc: 0.9901\n",
      "Epoch 3/3\n",
      "4457/4457 [==============================] - 339s 76ms/step - loss: 0.0027 - acc: 0.9989 - val_loss: 0.0505 - val_acc: 0.9901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4e64ac10>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, labels_train, batch_size=16, epochs=3,\n",
    "         validation_data=(test_data, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9998641e-01, 1.3642296e-05],\n",
       "       [9.9998808e-01, 1.1946274e-05],\n",
       "       [9.9999869e-01, 1.2670264e-06],\n",
       "       ...,\n",
       "       [9.9995065e-01, 4.9368144e-05],\n",
       "       [9.9999726e-01, 2.7452663e-06],\n",
       "       [9.9363649e-01, 6.3635134e-03]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction on test data\n",
    "predicted_blstm = model.predict(test_data)\n",
    "predicted_blstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.98979592 0.99259259]\n",
      "recall: [0.99897013 0.93055556]\n",
      "fscore: [0.99436187 0.96057348]\n",
      "support: [971 144]\n",
      "############################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       971\n",
      "           1       0.99      0.93      0.96       144\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1115\n",
      "   macro avg       0.99      0.96      0.98      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      " samples avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, support = score(labels_test, predicted_blstm.round())\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print(\"############################\")\n",
    "print(metrics.classification_report(labels_test, predicted_blstm.round()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
